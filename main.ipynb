{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss_cpu"
      ],
      "metadata": {
        "id": "KLyrVDknT3_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z90WJbhTwiR"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# GPT-2モデルとトークナイザーのロード\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# BERTモデルとトークナイザーのロード\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_sentence_vector(sentence, model, tokenizer):\n",
        "    \"\"\"文のベクトル化を行う関数\"\"\"\n",
        "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=128)\n",
        "    outputs = model(**inputs)\n",
        "    sentence_vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return sentence_vector.reshape(-1)\n",
        "\n",
        "def search_closest_question(query, index, qa_pairs, model, tokenizer):\n",
        "    \"\"\"FAISSインデックスを使用して、質問に最も近いQAペアを検索する関数\"\"\"\n",
        "    query_vector = get_sentence_vector(query, model, tokenizer)\n",
        "    D, I = index.search(np.array([query_vector]), k=1)\n",
        "    closest_pair = qa_pairs[I[0][0]]\n",
        "    return closest_pair\n",
        "\n",
        "# 質問と回答のペアのリスト\n",
        "qa_pairs = [\n",
        "    \"質問: 「注文した商品をどのように追跡しますか？」 回答: 「注文番号と電子メールアドレスを使用して、当社のウェブサイト上で注文を追跡できます。」\",\n",
        "    \"質問: 「製品の返品方法は？」 回答: 「製品は購入後30日以内に返品することができます。返品するには、オンラインフォームを記入してください。」\",\n",
        "    \"質問: 「支払い方法にはどのようなものがありますか？」 回答: 「クレジットカード、デビットカード、PayPal、銀行振込を受け付けています。」\",\n",
        "    \"質問: 「配送料金はいくらですか？」 回答: 「配送料金はお住まいの地域によって異なります。詳細はお支払いページをご覧ください。」\",\n",
        "    \"質問: 「商品はどれくらいの日数で届きますか？」 回答: 「通常、商品の配送には3〜5営業日かかります。」\",\n",
        "    \"質問: 「カスタマーサポートに連絡する方法は？」 回答: 「カスタマーサポートには電話、メール、お問い合わせフォームで連絡できます。詳細はお問い合わせページをご覧ください。」\",\n",
        "    \"質問: 「商品が壊れて届いた場合、どうすれば良いですか？」 回答: 「壊れた商品の場合、カスタマーサポートに連絡し、交換または返金の手続きを行ってください。」\",\n",
        "    \"質問: 「商品の在庫状況はどこで確認できますか？」 回答: 「商品の在庫状況は製品ページで確認できます。在庫がある場合、数量が表示されます。」\",\n",
        "    \"質問: 「注文をキャンセルする方法は？」 回答: 「注文をキャンセルするには、注文番号を入力し、カスタマーサポートに連絡してください。」\",\n",
        "    \"質問: 「返品送料は誰が負担しますか？」 回答: 「返品送料は、壊れた商品または誤った商品が送られた場合を除き、お客様の負担となります。」\",\n",
        "    \"質問: 「商品の保証期間はどのくらいですか？」 回答: 「商品の保証期間は通常1年です。詳細は製品の保証ポリシーをご確認ください。」\"\n",
        "]\n",
        "\n",
        "# 各ペアをベクトル化\n",
        "vectors = [get_sentence_vector(pair, bert_model, bert_tokenizer) for pair in qa_pairs]\n",
        "\n",
        "# FAISSを使用してベクトルデータベースを作成\n",
        "dim = vectors[0].shape[0]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.array(vectors))  # ベクトルを追加\n",
        "\n",
        "def generate_answer_with_gpt(document, query, tokenizer, model):\n",
        "    # パディングトークンの設定\n",
        "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
        "\n",
        "    \"\"\"文書と質問に基づいてGPT-2で回答を生成する関数\"\"\"\n",
        "    combined_input = query + \" \" + document\n",
        "    inputs = tokenizer.encode_plus(combined_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # GPT-2モデルで回答を生成\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=300)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# ユーザーからの質問\n",
        "user_question = \"支払い方法は何がありますか？\"\n",
        "\n",
        "# 関連するQAペアを検索\n",
        "closest_pair = search_closest_question(user_question, index, qa_pairs, bert_model, bert_tokenizer)\n",
        "\n",
        "# # GPT-2を使用して回答を生成\n",
        "# answer = generate_answer_with_gpt(closest_pair, user_question, gpt_tokenizer, gpt_model)\n",
        "# print(answer)\n",
        "\n",
        "# GPT-2モデルを使用して生成された回答から「回答:」の後の部分を抽出\n",
        "def extract_answer(text):\n",
        "    parts = text.split(\"回答: \")\n",
        "    if len(parts) > 1:\n",
        "        return parts[1].split(\"」\")[0]\n",
        "    else:\n",
        "        return \"回答が見つかりませんでした。\"\n",
        "\n",
        "# 回答を生成\n",
        "generated_answer = generate_answer_with_gpt(closest_pair, user_question, gpt_tokenizer, gpt_model)\n",
        "\n",
        "# 回答から必要な部分を抽出\n",
        "final_answer = extract_answer(generated_answer)\n",
        "print(final_answer)\n"
      ]
    }
  ]
}
